{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cda694-0f24-41d5-ad9d-e3739dc4ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import oracledb\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "import re\n",
    "import webbrowser\n",
    " \n",
    "#SCRE\n",
    "username = 'svcGOCUI'\n",
    "password = 'DELL2023support#'\n",
    "host = 'gocplorlvpr18.amer.dell.com'\n",
    "port = '1521'\n",
    "service_name = 'gooap_rw_oud_tls.prd.amer.dell.com'\n",
    " \n",
    "#DAO GE4 SIT\n",
    "# dbname=\"DAO_GE4\"\n",
    "# username = 'SIT_BROWSER'\n",
    "# password = 'browse_s1t'\n",
    "# host = 'udmnlorrrsi2a01.amer.dell.com'\n",
    "# port = '1521'\n",
    "# service_name = 'fdr4s.sit.amer.dell.com'\n",
    "excel_name=\"Input_Order_Incoming_Data.xlsx\"\n",
    "def Retrive_VectorData():\n",
    "    dsn = oracledb.makedsn(host, port, service_name=service_name)\n",
    "    try :\n",
    "        print(\"conn\")\n",
    "        connection = oracledb.connect(user=username, password=password, dsn=dsn)   \n",
    "        print(\"Connected to Oracle Database\")\n",
    "        cursor = connection.cursor()\n",
    "        # query = '''SELECT t.owner || '.' || t.table_name AS Table_Name,c.column_name as Column_Name FROM all_tables t \n",
    "        # JOIN all_tab_columns c ON t.table_name = c.table_name  ORDER BY t.table_name, c.column_name'''\n",
    " \n",
    "        query = '''select a.region, to_char(a.processdate_utc,'yyyymmdd') processday,to_char(a.processdate_utc,'hh24') as processday_hour,\n",
    "a.order_count,b.fiscalyear,b.fiscalquarter,b.fiscalmonth,b.fiscalweek,to_char(a.processdate_utc,'Day') as DayNum\n",
    "  from work.tb_orderprocess_effectiveness a,work.tb_fiscalcalendar b\n",
    "where to_char(a.processdate_utc,'yyyymmdd') between b.startdate and b.enddate\n",
    "   and a.functionname = 'Order Incoming'\n",
    "   and datatype = 'NEW'\n",
    "   and vendor = 'ALL'\n",
    "order by a.processdate_utc asc'''\n",
    " \n",
    "        cursor.execute(query)\n",
    " \n",
    "        rows = cursor.fetchall()\n",
    "        column_names = [desc[0] for desc in cursor.description]\n",
    "        data = pd.DataFrame(rows,columns=column_names)\n",
    "        print(excel_name)\n",
    "        data.to_excel(excel_name,index=False)\n",
    "        table = tabulate(rows, headers=column_names, tablefmt=\"pretty\")\n",
    "        print(data)\n",
    "        # data = pd.read_excel(\"DataFromDB.xlsx\")\n",
    "\n",
    "        # print(type(data))\n",
    "        # print(data)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "       print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n",
    "            print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce515e79-4d00-40b4-849e-7a117145d808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conn\n",
      "Connected to Oracle Database\n",
      "Input_Order_Incoming_Data.xlsx\n",
      "      REGION PROCESSDAY PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
      "0        DAO   20230101              00          414       FY23            Q4   \n",
      "1        APJ   20230101              00           27       FY23            Q4   \n",
      "2       EMEA   20230101              00            5       FY23            Q4   \n",
      "3        DAO   20230101              01          398       FY23            Q4   \n",
      "4        APJ   20230101              01           29       FY23            Q4   \n",
      "...      ...        ...             ...          ...        ...           ...   \n",
      "40876    DAO   20240806              03          371       FY25            Q3   \n",
      "40877    APJ   20240806              03          540       FY25            Q3   \n",
      "40878   EMEA   20240806              05           88       FY25            Q3   \n",
      "40879    APJ   20240806              05          516       FY25            Q3   \n",
      "40880    DAO   20240806              05          169       FY25            Q3   \n",
      "\n",
      "      FISCALMONTH FISCALWEEK     DAYNUM  \n",
      "0             M12       WK49  Sunday     \n",
      "1             M12       WK49  Sunday     \n",
      "2             M12       WK49  Sunday     \n",
      "3             M12       WK49  Sunday     \n",
      "4             M12       WK49  Sunday     \n",
      "...           ...        ...        ...  \n",
      "40876         M07       WK27  Tuesday    \n",
      "40877         M07       WK27  Tuesday    \n",
      "40878         M07       WK27  Tuesday    \n",
      "40879         M07       WK27  Tuesday    \n",
      "40880         M07       WK27  Tuesday    \n",
      "\n",
      "[40881 rows x 9 columns]\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "data = Retrive_VectorData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b7a4e8f-9d22-4514-84ff-97c2d6e92b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>PROCESSDAY</th>\n",
       "      <th>PROCESSDAY_HOUR</th>\n",
       "      <th>ORDER_COUNT</th>\n",
       "      <th>FISCALYEAR</th>\n",
       "      <th>FISCALQUARTER</th>\n",
       "      <th>FISCALMONTH</th>\n",
       "      <th>FISCALWEEK</th>\n",
       "      <th>DAYNUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>09</td>\n",
       "      <td>508</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAO</td>\n",
       "      <td>20240207</td>\n",
       "      <td>09</td>\n",
       "      <td>81</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>20240207</td>\n",
       "      <td>09</td>\n",
       "      <td>831</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>20240207</td>\n",
       "      <td>10</td>\n",
       "      <td>870</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>10</td>\n",
       "      <td>377</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REGION PROCESSDAY PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
       "0    APJ   20240207              09          508       FY25            Q1   \n",
       "1    DAO   20240207              09           81       FY25            Q1   \n",
       "2   EMEA   20240207              09          831       FY25            Q1   \n",
       "3   EMEA   20240207              10          870       FY25            Q1   \n",
       "4    APJ   20240207              10          377       FY25            Q1   \n",
       "\n",
       "  FISCALMONTH FISCALWEEK     DAYNUM  \n",
       "0         M01       WK01  Wednesday  \n",
       "1         M01       WK01  Wednesday  \n",
       "2         M01       WK01  Wednesday  \n",
       "3         M01       WK01  Wednesday  \n",
       "4         M01       WK01  Wednesday  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cac3a8ff-55ac-4e5a-b4c2-78ed05192c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uploading out put file into SQL DB\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# from sqlalchemy.types import Integer, String, DateTime, Numeric\n",
    "# import cx_Oracle\n",
    " \n",
    "# #SCRE\n",
    "# username = 'svcGOCUI'\n",
    "# password = 'DELL2023support#'\n",
    "# host = 'gocplorlvpr18.amer.dell.com'\n",
    "# port = '1521'\n",
    "# service_name = 'gooap_rw_oud_tls.prd.amer.dell.com'\n",
    "# dsn = oracledb.makedsn(host, port, service_name=service_name)\n",
    " \n",
    "# engine = create_engine(f'oracle+cx_oracle://{username}:{password}@{dsn}')\n",
    "# dtype = {\n",
    "#     'REGION': String(256), \n",
    "#     'FORECAST_DATE': DateTime,\n",
    "#     'MODEL1': Numeric,\n",
    "#     'MODEL2': Numeric,\n",
    "#     'MODEL3': Numeric,\n",
    "#     'MODEL4': Numeric,\n",
    "#     'MODEL5': Numeric,\n",
    "#     'ACTUALORDERUNIT': Numeric,\n",
    "#     'CREATED_DATE': DateTime,\n",
    "#     'UPDATED_DATE': DateTime,\n",
    "# }\n",
    " \n",
    "# try:\n",
    "#     data = pd.read_csv(r\"C:/Users/S_Munwar/Downloads/Final_Model_for_OIF/Future_forecasted_OIF_SQL.csv\")\n",
    "#     print(type(data))\n",
    "#     data['FORECAST_DATE'] = pd.to_datetime(data['FORECAST_DATE'])\n",
    "#     data['CREATED_DATE'] = pd.to_datetime(data['CREATED_DATE'])\n",
    "#     data['UPDATED_DATE'] = pd.to_datetime(data['UPDATED_DATE'])\n",
    "#     print(type(data))\n",
    "#     data.to_sql('tb_orderprocess_effectiveness_forecast',schema ='work', con=engine, if_exists='append', index=False)\n",
    "#     print(\"added successfully\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "# finally:\n",
    "#     engine.dispose()\n",
    "#     print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295459a-7485-4201-96d5-18e89fcc4e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32952368-3e48-4eba-982f-a023c5fa3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV\n",
    "# data = pd.read_csv(\"C:\\\\Users\\\\S_Munwar\\\\Downloads\\\\Input_Order_Incoming_Data.csv\")\n",
    "#data =pd.read_excel(\"C:\\\\Users\\\\S_Munwar\\\\Downloads\\\\Input_Order_Incoming_Data.xlsx\")\n",
    "\n",
    "\n",
    "# Convert PROCESSDAY to proper date format\n",
    "data[\"PROCESSDAY\"] = pd.to_datetime(data[\"PROCESSDAY\"], format=\"%Y%m%d\")\n",
    "\n",
    "data[\"PROCESSDAY_HOUR\"] = data[\"PROCESSDAY_HOUR\"].astype(int)\n",
    "# Create a new column combining PROCESSDAY and PROCESSDAY_HOUR\n",
    "data[\"DateTime\"] = data[\"PROCESSDAY\"] + pd.to_timedelta(data[\"PROCESSDAY_HOUR\"], unit=\"h\")\n",
    "\n",
    "# Drop the index column\n",
    "#data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473c278f-71a0-48e6-8a82-34bace81b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= data.drop(columns=['PROCESSDAY', 'PROCESSDAY'])\n",
    "df=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434e8489-d6bf-4acf-8734-d966e65d051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMEA DataFrame:\n",
      "      REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR  \\\n",
      "2       EMEA 2023-01-01                0            5       FY23   \n",
      "5       EMEA 2023-01-01                1            8       FY23   \n",
      "8       EMEA 2023-01-01                2            2       FY23   \n",
      "15      EMEA 2023-01-01                5            6       FY23   \n",
      "18      EMEA 2023-01-01                6            1       FY23   \n",
      "...      ...        ...              ...          ...        ...   \n",
      "40867   EMEA 2024-08-05               23           24       FY25   \n",
      "40869   EMEA 2024-08-06                1            3       FY25   \n",
      "40872   EMEA 2024-08-06                2           10       FY25   \n",
      "40875   EMEA 2024-08-06                3           93       FY25   \n",
      "40878   EMEA 2024-08-06                5           88       FY25   \n",
      "\n",
      "      FISCALQUARTER FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
      "2                Q4         M12       WK49  Sunday    2023-01-01 00:00:00  \n",
      "5                Q4         M12       WK49  Sunday    2023-01-01 01:00:00  \n",
      "8                Q4         M12       WK49  Sunday    2023-01-01 02:00:00  \n",
      "15               Q4         M12       WK49  Sunday    2023-01-01 05:00:00  \n",
      "18               Q4         M12       WK49  Sunday    2023-01-01 06:00:00  \n",
      "...             ...         ...        ...        ...                 ...  \n",
      "40867            Q3         M07       WK27  Monday    2024-08-05 23:00:00  \n",
      "40869            Q3         M07       WK27  Tuesday   2024-08-06 01:00:00  \n",
      "40872            Q3         M07       WK27  Tuesday   2024-08-06 02:00:00  \n",
      "40875            Q3         M07       WK27  Tuesday   2024-08-06 03:00:00  \n",
      "40878            Q3         M07       WK27  Tuesday   2024-08-06 05:00:00  \n",
      "\n",
      "[13554 rows x 10 columns]\n",
      "\n",
      "DAO DataFrame:\n",
      "      REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR  \\\n",
      "0        DAO 2023-01-01                0          414       FY23   \n",
      "3        DAO 2023-01-01                1          398       FY23   \n",
      "6        DAO 2023-01-01                2          527       FY23   \n",
      "10       DAO 2023-01-01                3          446       FY23   \n",
      "12       DAO 2023-01-01                4          432       FY23   \n",
      "...      ...        ...              ...          ...        ...   \n",
      "40868    DAO 2024-08-05               23         1076       FY25   \n",
      "40871    DAO 2024-08-06                1          853       FY25   \n",
      "40873    DAO 2024-08-06                2          515       FY25   \n",
      "40876    DAO 2024-08-06                3          371       FY25   \n",
      "40880    DAO 2024-08-06                5          169       FY25   \n",
      "\n",
      "      FISCALQUARTER FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
      "0                Q4         M12       WK49  Sunday    2023-01-01 00:00:00  \n",
      "3                Q4         M12       WK49  Sunday    2023-01-01 01:00:00  \n",
      "6                Q4         M12       WK49  Sunday    2023-01-01 02:00:00  \n",
      "10               Q4         M12       WK49  Sunday    2023-01-01 03:00:00  \n",
      "12               Q4         M12       WK49  Sunday    2023-01-01 04:00:00  \n",
      "...             ...         ...        ...        ...                 ...  \n",
      "40868            Q3         M07       WK27  Monday    2024-08-05 23:00:00  \n",
      "40871            Q3         M07       WK27  Tuesday   2024-08-06 01:00:00  \n",
      "40873            Q3         M07       WK27  Tuesday   2024-08-06 02:00:00  \n",
      "40876            Q3         M07       WK27  Tuesday   2024-08-06 03:00:00  \n",
      "40880            Q3         M07       WK27  Tuesday   2024-08-06 05:00:00  \n",
      "\n",
      "[13736 rows x 10 columns]\n",
      "\n",
      "APJ DataFrame:\n",
      "      REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR  \\\n",
      "1        APJ 2023-01-01                0           27       FY23   \n",
      "4        APJ 2023-01-01                1           29       FY23   \n",
      "7        APJ 2023-01-01                2           45       FY23   \n",
      "9        APJ 2023-01-01                3           82       FY23   \n",
      "11       APJ 2023-01-01                4           32       FY23   \n",
      "...      ...        ...              ...          ...        ...   \n",
      "40866    APJ 2024-08-05               23           80       FY25   \n",
      "40870    APJ 2024-08-06                1          437       FY25   \n",
      "40874    APJ 2024-08-06                2          715       FY25   \n",
      "40877    APJ 2024-08-06                3          540       FY25   \n",
      "40879    APJ 2024-08-06                5          516       FY25   \n",
      "\n",
      "      FISCALQUARTER FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
      "1                Q4         M12       WK49  Sunday    2023-01-01 00:00:00  \n",
      "4                Q4         M12       WK49  Sunday    2023-01-01 01:00:00  \n",
      "7                Q4         M12       WK49  Sunday    2023-01-01 02:00:00  \n",
      "9                Q4         M12       WK49  Sunday    2023-01-01 03:00:00  \n",
      "11               Q4         M12       WK49  Sunday    2023-01-01 04:00:00  \n",
      "...             ...         ...        ...        ...                 ...  \n",
      "40866            Q3         M07       WK27  Monday    2024-08-05 23:00:00  \n",
      "40870            Q3         M07       WK27  Tuesday   2024-08-06 01:00:00  \n",
      "40874            Q3         M07       WK27  Tuesday   2024-08-06 02:00:00  \n",
      "40877            Q3         M07       WK27  Tuesday   2024-08-06 03:00:00  \n",
      "40879            Q3         M07       WK27  Tuesday   2024-08-06 05:00:00  \n",
      "\n",
      "[13591 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separate dataframes for each region\n",
    "emea_df = df[df[\"REGION\"] == \"EMEA\"]\n",
    "dao_df = df[df[\"REGION\"] == \"DAO\"]\n",
    "apj_df = df[df[\"REGION\"] == \"APJ\"]\n",
    "\n",
    "# Print the dataframes\n",
    "print(\"EMEA DataFrame:\")\n",
    "print(emea_df)\n",
    "print(\"\\nDAO DataFrame:\")\n",
    "print(dao_df)\n",
    "print(\"\\nAPJ DataFrame:\")\n",
    "print(apj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "125af797-7187-48e4-ab98-4f2a2f893b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:28: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data for EMEA saved to EMEA_imputated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:28: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data for DAO saved to DAO_imputated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:28: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_30052\\2086939258.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data for APJ saved to APJ_imputated.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Missing Values imputations for 3 regions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming df is your original DataFrame with all regions\n",
    "emea_df = df[df[\"REGION\"] == \"EMEA\"]\n",
    "dao_df = df[df[\"REGION\"] == \"DAO\"]\n",
    "apj_df = df[df[\"REGION\"] == \"APJ\"]\n",
    "\n",
    "# Define a function for imputation\n",
    "def perform_imputation(df, region_name):\n",
    "    # Convert DateTime column to datetime format\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "\n",
    "    # Generate 1-hour intervals\n",
    "    start_date = df[\"DateTime\"].min()\n",
    "    end_date = df[\"DateTime\"].max()\n",
    "    hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
    "\n",
    "    # Create a new DataFrame with intervals\n",
    "    interval_df = pd.DataFrame({\"DateTime\": hour_intervals})\n",
    "\n",
    "    # Merge interval_df with original data\n",
    "    merged_df = pd.merge(interval_df, df, on=\"DateTime\", how=\"left\")\n",
    "\n",
    "    # Fill missing data based on available data\n",
    "    merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "    # Perform imputation for ORDER_COUNT using DAYNUM\n",
    "    daynum_order_count_avg = merged_df.groupby(\"DAYNUM\")[\"ORDER_COUNT\"].mean()\n",
    "    merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
    "\n",
    "    # Fill remaining columns based on data & time columns\n",
    "    merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n",
    "\n",
    "    # Save the imputed DataFrame to an Excel file\n",
    "    output_path = f\"{region_name}_imputated.xlsx\"\n",
    "    merged_df.to_excel(output_path, index=False)\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    print(f\"Imputed data for {region_name} saved to {output_path}\")\n",
    "\n",
    "# Perform imputation for each region\n",
    "for region_df, region_name in zip([emea_df, dao_df, apj_df], [\"EMEA\", \"DAO\", \"APJ\"]):\n",
    "    perform_imputation(region_df, region_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "059f5b19-4137-48cb-947a-9fbe2fe4558d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>PROCESSDAY</th>\n",
       "      <th>PROCESSDAY_HOUR</th>\n",
       "      <th>ORDER_COUNT</th>\n",
       "      <th>FISCALYEAR</th>\n",
       "      <th>FISCALQUARTER</th>\n",
       "      <th>FISCALMONTH</th>\n",
       "      <th>FISCALWEEK</th>\n",
       "      <th>DAYNUM</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>9</td>\n",
       "      <td>831</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>10</td>\n",
       "      <td>870</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>11</td>\n",
       "      <td>897</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>12</td>\n",
       "      <td>875</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>13</td>\n",
       "      <td>924</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 13:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
       "2    EMEA 2024-02-07                9          831       FY25            Q1   \n",
       "3    EMEA 2024-02-07               10          870       FY25            Q1   \n",
       "7    EMEA 2024-02-07               11          897       FY25            Q1   \n",
       "11   EMEA 2024-02-07               12          875       FY25            Q1   \n",
       "13   EMEA 2024-02-07               13          924       FY25            Q1   \n",
       "\n",
       "   FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
       "2          M01       WK01  Wednesday 2024-02-07 09:00:00  \n",
       "3          M01       WK01  Wednesday 2024-02-07 10:00:00  \n",
       "7          M01       WK01  Wednesday 2024-02-07 11:00:00  \n",
       "11         M01       WK01  Wednesday 2024-02-07 12:00:00  \n",
       "13         M01       WK01  Wednesday 2024-02-07 13:00:00  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emea_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f22f5c09-f9e5-4484-ba33-4aea6c672cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns for EMEA:\n",
      "             DateTime  ORDER_COUNT\n",
      "0 2024-02-07 09:00:00          831\n",
      "1 2024-02-07 10:00:00          870\n",
      "2 2024-02-07 11:00:00          897\n",
      "3 2024-02-07 12:00:00          875\n",
      "4 2024-02-07 13:00:00          924\n",
      "\n",
      "Selected columns for DAO:\n",
      "             DateTime  ORDER_COUNT\n",
      "0 2024-02-07 09:00:00           81\n",
      "1 2024-02-07 10:00:00          111\n",
      "2 2024-02-07 11:00:00          184\n",
      "3 2024-02-07 12:00:00          729\n",
      "4 2024-02-07 13:00:00          999\n",
      "\n",
      "Selected columns for APJ:\n",
      "             DateTime  ORDER_COUNT\n",
      "0 2024-02-07 09:00:00          508\n",
      "1 2024-02-07 10:00:00          377\n",
      "2 2024-02-07 11:00:00          264\n",
      "3 2024-02-07 12:00:00          146\n",
      "4 2024-02-07 13:00:00           97\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to select specific columns from a DataFrame\n",
    "def select_columns(df, columns):\n",
    "    return df[columns].reset_index(drop=True)\n",
    "\n",
    "# Define the columns to select\n",
    "selected_columns = [\"DateTime\", \"ORDER_COUNT\"]\n",
    "\n",
    "# Assuming emea_df, dao_df, and apj_df are your DataFrames for the EMEA, DAO, and APJ regions respectively\n",
    "# Apply the function to each DataFrame\n",
    "data_emea = select_columns(emea_df, selected_columns)\n",
    "data_dao = select_columns(dao_df, selected_columns)\n",
    "data_apj = select_columns(apj_df, selected_columns)\n",
    "\n",
    "# Now you have the selected columns for each region\n",
    "print(\"Selected columns for EMEA:\")\n",
    "print(data_emea.head())\n",
    "\n",
    "print(\"\\nSelected columns for DAO:\")\n",
    "print(data_dao.head())\n",
    "\n",
    "print(\"\\nSelected columns for APJ:\")\n",
    "print(data_apj.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bf4d1b9-2c8e-45f4-854a-a4a4f0830b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMEA - Decision Tree MSE: 25316.587668137876\n",
      "EMEA - Random Forest MSE: 23184.29621400312\n",
      "EMEA - GBM MSE: 16718.94683008091\n",
      "EMEA - SVM MSE: 96897.07505086665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_43120\\316647103.py:60: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to ML_forecast_results_EMEA_.xlsx for EMEA\n",
      "DAO - Decision Tree MSE: 283180.62128433783\n",
      "DAO - Random Forest MSE: 262584.7768208985\n",
      "DAO - GBM MSE: 202656.01606162518\n",
      "DAO - SVM MSE: 1244551.7605709522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_43120\\316647103.py:60: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to ML_forecast_results_DAO_.xlsx for DAO\n",
      "APJ - Decision Tree MSE: 35382.870161514904\n",
      "APJ - Random Forest MSE: 32404.18142475029\n",
      "APJ - GBM MSE: 23508.216303361118\n",
      "APJ - SVM MSE: 81396.33703120888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_43120\\316647103.py:60: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to ML_forecast_results_APJ_.xlsx for APJ\n"
     ]
    }
   ],
   "source": [
    "# Forecasting Models for 3 Regions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def process_region(data, region_name):\n",
    "    # Feature engineering for seasonality\n",
    "    data['hour'] = data.index.hour\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    data['month'] = data.index.month\n",
    "\n",
    "    # Prepare features and target with seasonality\n",
    "    X = data[['hour', 'dayofweek', 'month']]  # Add more features as needed\n",
    "    y = data['ORDER_COUNT']\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train your models here (Decision Tree, Random Forest, Gradient Boosting, SVM)\n",
    "    # Decision Tree Regressor\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    dt_predictions = dt_model.predict(X_test)\n",
    "    dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "    print(f'{region_name} - Decision Tree MSE: {dt_mse}')\n",
    "\n",
    "    # Random Forest Regressor\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "    print(f'{region_name} - Random Forest MSE: {rf_mse}')\n",
    "\n",
    "    # Gradient Boosting Regressor\n",
    "    gbm_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    gbm_model.fit(X_train, y_train)\n",
    "    gbm_predictions = gbm_model.predict(X_test)\n",
    "    gbm_mse = mean_squared_error(y_test, gbm_predictions)\n",
    "    print(f'{region_name} - GBM MSE: {gbm_mse}')\n",
    "\n",
    "    # Support Vector Machine Regressor\n",
    "    svm_model = SVR(kernel='rbf')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_predictions = svm_model.predict(X_test)\n",
    "    svm_mse = mean_squared_error(y_test, svm_predictions)\n",
    "    print(f'{region_name} - SVM MSE: {svm_mse}')\n",
    "\n",
    "    # Combine actual and forecasted values into DataFrames for comparison\n",
    "    actual_vs_forecasted_dt = pd.DataFrame({'Actual': y_test, 'Forecasted_DT': dt_predictions})\n",
    "    actual_vs_forecasted_rf = pd.DataFrame({'Actual': y_test, 'Forecasted_RF': rf_predictions})\n",
    "    actual_vs_forecasted_gbm = pd.DataFrame({'Actual': y_test, 'Forecasted_GBM': gbm_predictions})\n",
    "    actual_vs_forecasted_svm = pd.DataFrame({'Actual': y_test, 'Forecasted_SVM': svm_predictions})\n",
    "\n",
    "    # Extend the datetime index for the next 100 future values with 1-hour interval\n",
    "    last_timestamp = data.index[-1]\n",
    "    future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n",
    "\n",
    "    # Create a DataFrame for future dates and engineer seasonality features\n",
    "    future_df = pd.DataFrame(index=future_dates)\n",
    "    future_df['hour'] = future_df.index.hour\n",
    "    future_df['dayofweek'] = future_df.index.dayofweek\n",
    "    future_df['month'] = future_df.index.month\n",
    "\n",
    "    # Predict the next 100 future values using each model\n",
    "    future_predictions_dt = dt_model.predict(future_df)\n",
    "    future_predictions_rf = rf_model.predict(future_df)\n",
    "    future_predictions_gbm = gbm_model.predict(future_df)\n",
    "    future_predictions_svm = svm_model.predict(future_df)\n",
    "\n",
    "    # Create a DataFrame for the future predictions\n",
    "    future_predictions_df = pd.DataFrame({\n",
    "        'DateTime': future_dates,\n",
    "        'Forecasted_DT': future_predictions_dt,\n",
    "        'Forecasted_RF': future_predictions_rf,\n",
    "        'Forecasted_GBM': future_predictions_gbm,\n",
    "        'Forecasted_SVM': future_predictions_svm\n",
    "    })\n",
    "\n",
    "    # Set the DateTime as the index\n",
    "    future_predictions_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "    # Combine actual vs forecasted and future forecasted values into a single DataFrame\n",
    "    combined_results_df = pd.concat([\n",
    "        actual_vs_forecasted_dt,\n",
    "        actual_vs_forecasted_rf[['Forecasted_RF']],\n",
    "        actual_vs_forecasted_gbm[['Forecasted_GBM']],\n",
    "        actual_vs_forecasted_svm[['Forecasted_SVM']],\n",
    "        future_predictions_df\n",
    "    ], axis=1)\n",
    "\n",
    "    # Define the output path for the Excel file\n",
    "    output_excel_path = f'ML_forecast_results_{region_name}_.xlsx'\n",
    "\n",
    "    # Export the DataFrame to an Excel file\n",
    "    combined_results_df.to_excel(output_excel_path, index=True)\n",
    "\n",
    "    print(f\"Data exported to {output_excel_path} for {region_name}\")\n",
    "\n",
    "# Load your datasets\n",
    "data_emea = pd.DataFrame(data_emea)\n",
    "data_emea['DateTime'] = pd.to_datetime(data_emea['DateTime'])\n",
    "data_emea.set_index('DateTime', inplace=True)\n",
    "data_dao = pd.DataFrame(data_dao)\n",
    "data_dao['DateTime'] = pd.to_datetime(data_dao['DateTime'])\n",
    "data_dao.set_index('DateTime', inplace=True)\n",
    "data_apj = pd.DataFrame(data_apj)\n",
    "data_apj['DateTime'] = pd.to_datetime(data_apj['DateTime'])\n",
    "data_apj.set_index('DateTime', inplace=True)\n",
    "\n",
    "\n",
    "# Process each region\n",
    "process_region(data_emea, 'EMEA')\n",
    "process_region(data_dao, 'DAO')\n",
    "process_region(data_apj, 'APJ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b29f6c-ad72-4cfc-8645-900171f48c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33179fbc-e2da-40ad-b135-143ccdd138a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04277fe5-a3e2-42ee-a35c-ed41dce53141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1729b1-9d35-476a-993b-ded80d9f6420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f2ef9-79cf-44d0-ac4a-4d5e2b553105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565335e-a4ac-493b-b803-bbe1c25411dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc97cdc-6aef-4e5c-b6df-5cad4e129d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73928511-8aab-4b9b-a172-0ead2b4f8fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
