{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cda694-0f24-41d5-ad9d-e3739dc4ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import oracledb\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "import re\n",
    "import webbrowser\n",
    " \n",
    "#SCRE\n",
    "username = 'svcGOCUI'\n",
    "password = 'DELL2023support#'\n",
    "host = 'gocplorlvpr18.amer.dell.com'\n",
    "port = '1521'\n",
    "service_name = 'gooap_rw_oud_tls.prd.amer.dell.com'\n",
    " \n",
    "#DAO GE4 SIT\n",
    "# dbname=\"DAO_GE4\"\n",
    "# username = 'SIT_BROWSER'\n",
    "# password = 'browse_s1t'\n",
    "# host = 'udmnlorrrsi2a01.amer.dell.com'\n",
    "# port = '1521'\n",
    "# service_name = 'fdr4s.sit.amer.dell.com'\n",
    "excel_name=\"Input_Order_Incoming_Data.xlsx\"\n",
    "def Retrive_VectorData():\n",
    "    dsn = oracledb.makedsn(host, port, service_name=service_name)\n",
    "    try :\n",
    "        print(\"conn\")\n",
    "        connection = oracledb.connect(user=username, password=password, dsn=dsn)   \n",
    "        print(\"Connected to Oracle Database\")\n",
    "        cursor = connection.cursor()\n",
    "        # query = '''SELECT t.owner || '.' || t.table_name AS Table_Name,c.column_name as Column_Name FROM all_tables t \n",
    "        # JOIN all_tab_columns c ON t.table_name = c.table_name  ORDER BY t.table_name, c.column_name'''\n",
    " \n",
    "        query = '''select a.region, to_char(a.processdate_utc,'yyyymmdd') processday,to_char(a.processdate_utc,'hh24') as processday_hour,\n",
    "a.order_count,b.fiscalyear,b.fiscalquarter,b.fiscalmonth,b.fiscalweek,to_char(a.processdate_utc,'Day') as DayNum\n",
    "  from work.tb_orderprocess_effectiveness a,work.tb_fiscalcalendar b\n",
    "where to_char(a.processdate_utc,'yyyymmdd') between b.startdate and b.enddate\n",
    "   and a.functionname = 'Order Incoming'\n",
    "   and datatype = 'NEW'\n",
    "   and vendor = 'ALL'\n",
    "order by a.processdate_utc asc'''\n",
    " \n",
    "        cursor.execute(query)\n",
    " \n",
    "        rows = cursor.fetchall()\n",
    "        column_names = [desc[0] for desc in cursor.description]\n",
    "        data = pd.DataFrame(rows,columns=column_names)\n",
    "        print(excel_name)\n",
    "        data.to_excel(excel_name,index=False)\n",
    "        table = tabulate(rows, headers=column_names, tablefmt=\"pretty\")\n",
    "        print(data)\n",
    "        # data = pd.read_excel(\"DataFromDB.xlsx\")\n",
    "\n",
    "        # print(type(data))\n",
    "        # print(data)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "       print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n",
    "            print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce515e79-4d00-40b4-849e-7a117145d808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conn\n",
      "Connected to Oracle Database\n",
      "Input_Order_Incoming_Data.xlsx\n",
      "      REGION PROCESSDAY PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
      "0       EMEA   20240207              09          831       FY25            Q1   \n",
      "1        DAO   20240207              09           81       FY25            Q1   \n",
      "2        APJ   20240207              09          508       FY25            Q1   \n",
      "3       EMEA   20240207              10          870       FY25            Q1   \n",
      "4        APJ   20240207              10          377       FY25            Q1   \n",
      "...      ...        ...             ...          ...        ...           ...   \n",
      "11879    APJ   20240729              08          776       FY25            Q2   \n",
      "11880    DAO   20240729              08           56       FY25            Q2   \n",
      "11881   EMEA   20240729              09          877       FY25            Q2   \n",
      "11882    DAO   20240729              09           46       FY25            Q2   \n",
      "11883    APJ   20240729              09          799       FY25            Q2   \n",
      "\n",
      "      FISCALMONTH FISCALWEEK     DAYNUM  \n",
      "0             M01       WK01  Wednesday  \n",
      "1             M01       WK01  Wednesday  \n",
      "2             M01       WK01  Wednesday  \n",
      "3             M01       WK01  Wednesday  \n",
      "4             M01       WK01  Wednesday  \n",
      "...           ...        ...        ...  \n",
      "11879         M06       WK26  Monday     \n",
      "11880         M06       WK26  Monday     \n",
      "11881         M06       WK26  Monday     \n",
      "11882         M06       WK26  Monday     \n",
      "11883         M06       WK26  Monday     \n",
      "\n",
      "[11884 rows x 9 columns]\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "data = Retrive_VectorData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7a4e8f-9d22-4514-84ff-97c2d6e92b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>PROCESSDAY</th>\n",
       "      <th>PROCESSDAY_HOUR</th>\n",
       "      <th>ORDER_COUNT</th>\n",
       "      <th>FISCALYEAR</th>\n",
       "      <th>FISCALQUARTER</th>\n",
       "      <th>FISCALMONTH</th>\n",
       "      <th>FISCALWEEK</th>\n",
       "      <th>DAYNUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>20240207</td>\n",
       "      <td>09</td>\n",
       "      <td>831</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAO</td>\n",
       "      <td>20240207</td>\n",
       "      <td>09</td>\n",
       "      <td>81</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>09</td>\n",
       "      <td>508</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>20240207</td>\n",
       "      <td>10</td>\n",
       "      <td>870</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>10</td>\n",
       "      <td>377</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REGION PROCESSDAY PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
       "0   EMEA   20240207              09          831       FY25            Q1   \n",
       "1    DAO   20240207              09           81       FY25            Q1   \n",
       "2    APJ   20240207              09          508       FY25            Q1   \n",
       "3   EMEA   20240207              10          870       FY25            Q1   \n",
       "4    APJ   20240207              10          377       FY25            Q1   \n",
       "\n",
       "  FISCALMONTH FISCALWEEK     DAYNUM  \n",
       "0         M01       WK01  Wednesday  \n",
       "1         M01       WK01  Wednesday  \n",
       "2         M01       WK01  Wednesday  \n",
       "3         M01       WK01  Wednesday  \n",
       "4         M01       WK01  Wednesday  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3a8ff-55ac-4e5a-b4c2-78ed05192c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uploading out put file into SQL DB\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# from sqlalchemy.types import Integer, String, DateTime, Numeric\n",
    "# import cx_Oracle\n",
    " \n",
    "# #SCRE\n",
    "# username = 'svcGOCUI'\n",
    "# password = 'DELL2023support#'\n",
    "# host = 'gocplorlvpr18.amer.dell.com'\n",
    "# port = '1521'\n",
    "# service_name = 'gooap_rw_oud_tls.prd.amer.dell.com'\n",
    "# dsn = oracledb.makedsn(host, port, service_name=service_name)\n",
    " \n",
    "# engine = create_engine(f'oracle+cx_oracle://{username}:{password}@{dsn}')\n",
    "# dtype = {\n",
    "#     'REGION': String(256), \n",
    "#     'FORECAST_DATE': DateTime,\n",
    "#     'MODEL1': Numeric,\n",
    "#     'MODEL2': Numeric,\n",
    "#     'MODEL3': Numeric,\n",
    "#     'MODEL4': Numeric,\n",
    "#     'MODEL5': Numeric,\n",
    "#     'ACTUALORDERUNIT': Numeric,\n",
    "#     'CREATED_DATE': DateTime,\n",
    "#     'UPDATED_DATE': DateTime,\n",
    "# }\n",
    " \n",
    "# try:\n",
    "#     data = pd.read_csv(r\"C:/Users/S_Munwar/Downloads/Final_Model_for_OIF/Future_forecasted_OIF_SQL.csv\")\n",
    "#     print(type(data))\n",
    "#     data['FORECAST_DATE'] = pd.to_datetime(data['FORECAST_DATE'])\n",
    "#     data['CREATED_DATE'] = pd.to_datetime(data['CREATED_DATE'])\n",
    "#     data['UPDATED_DATE'] = pd.to_datetime(data['UPDATED_DATE'])\n",
    "#     print(type(data))\n",
    "#     data.to_sql('tb_orderprocess_effectiveness_forecast',schema ='work', con=engine, if_exists='append', index=False)\n",
    "#     print(\"added successfully\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "# finally:\n",
    "#     engine.dispose()\n",
    "#     print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295459a-7485-4201-96d5-18e89fcc4e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32952368-3e48-4eba-982f-a023c5fa3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV\n",
    "# data = pd.read_csv(\"C:\\\\Users\\\\S_Munwar\\\\Downloads\\\\Input_Order_Incoming_Data.csv\")\n",
    "#data =pd.read_excel(\"C:\\\\Users\\\\S_Munwar\\\\Downloads\\\\Input_Order_Incoming_Data.xlsx\")\n",
    "\n",
    "\n",
    "# Convert PROCESSDAY to proper date format\n",
    "data[\"PROCESSDAY\"] = pd.to_datetime(data[\"PROCESSDAY\"], format=\"%Y%m%d\")\n",
    "\n",
    "data[\"PROCESSDAY_HOUR\"] = data[\"PROCESSDAY_HOUR\"].astype(int)\n",
    "# Create a new column combining PROCESSDAY and PROCESSDAY_HOUR\n",
    "data[\"DateTime\"] = data[\"PROCESSDAY\"] + pd.to_timedelta(data[\"PROCESSDAY_HOUR\"], unit=\"h\")\n",
    "\n",
    "# Drop the index column\n",
    "#data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473c278f-71a0-48e6-8a82-34bace81b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= data.drop(columns=['PROCESSDAY', 'PROCESSDAY'])\n",
    "df=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434e8489-d6bf-4acf-8734-d966e65d051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMEA DataFrame:\n",
      "      REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR  \\\n",
      "0       EMEA 2024-02-07                9          831       FY25   \n",
      "3       EMEA 2024-02-07               10          870       FY25   \n",
      "8       EMEA 2024-02-07               11          897       FY25   \n",
      "11      EMEA 2024-02-07               12          875       FY25   \n",
      "14      EMEA 2024-02-07               13          924       FY25   \n",
      "...      ...        ...              ...          ...        ...   \n",
      "11871   EMEA 2024-07-29                5           86       FY25   \n",
      "11874   EMEA 2024-07-29                6          117       FY25   \n",
      "11875   EMEA 2024-07-29                7          340       FY25   \n",
      "11878   EMEA 2024-07-29                8          564       FY25   \n",
      "11881   EMEA 2024-07-29                9          877       FY25   \n",
      "\n",
      "      FISCALQUARTER FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
      "0                Q1         M01       WK01  Wednesday 2024-02-07 09:00:00  \n",
      "3                Q1         M01       WK01  Wednesday 2024-02-07 10:00:00  \n",
      "8                Q1         M01       WK01  Wednesday 2024-02-07 11:00:00  \n",
      "11               Q1         M01       WK01  Wednesday 2024-02-07 12:00:00  \n",
      "14               Q1         M01       WK01  Wednesday 2024-02-07 13:00:00  \n",
      "...             ...         ...        ...        ...                 ...  \n",
      "11871            Q2         M06       WK26  Monday    2024-07-29 05:00:00  \n",
      "11874            Q2         M06       WK26  Monday    2024-07-29 06:00:00  \n",
      "11875            Q2         M06       WK26  Monday    2024-07-29 07:00:00  \n",
      "11878            Q2         M06       WK26  Monday    2024-07-29 08:00:00  \n",
      "11881            Q2         M06       WK26  Monday    2024-07-29 09:00:00  \n",
      "\n",
      "[3921 rows x 10 columns]\n",
      "\n",
      "DAO DataFrame:\n",
      "      REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR  \\\n",
      "1        DAO 2024-02-07                9           81       FY25   \n",
      "5        DAO 2024-02-07               10          111       FY25   \n",
      "6        DAO 2024-02-07               11          184       FY25   \n",
      "9        DAO 2024-02-07               12          729       FY25   \n",
      "13       DAO 2024-02-07               13          999       FY25   \n",
      "...      ...        ...              ...          ...        ...   \n",
      "11869    DAO 2024-07-29                5          103       FY25   \n",
      "11873    DAO 2024-07-29                6           96       FY25   \n",
      "11877    DAO 2024-07-29                7           93       FY25   \n",
      "11880    DAO 2024-07-29                8           56       FY25   \n",
      "11882    DAO 2024-07-29                9           46       FY25   \n",
      "\n",
      "      FISCALQUARTER FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
      "1                Q1         M01       WK01  Wednesday 2024-02-07 09:00:00  \n",
      "5                Q1         M01       WK01  Wednesday 2024-02-07 10:00:00  \n",
      "6                Q1         M01       WK01  Wednesday 2024-02-07 11:00:00  \n",
      "9                Q1         M01       WK01  Wednesday 2024-02-07 12:00:00  \n",
      "13               Q1         M01       WK01  Wednesday 2024-02-07 13:00:00  \n",
      "...             ...         ...        ...        ...                 ...  \n",
      "11869            Q2         M06       WK26  Monday    2024-07-29 05:00:00  \n",
      "11873            Q2         M06       WK26  Monday    2024-07-29 06:00:00  \n",
      "11877            Q2         M06       WK26  Monday    2024-07-29 07:00:00  \n",
      "11880            Q2         M06       WK26  Monday    2024-07-29 08:00:00  \n",
      "11882            Q2         M06       WK26  Monday    2024-07-29 09:00:00  \n",
      "\n",
      "[4021 rows x 10 columns]\n",
      "\n",
      "APJ DataFrame:\n",
      "      REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR  \\\n",
      "2        APJ 2024-02-07                9          508       FY25   \n",
      "4        APJ 2024-02-07               10          377       FY25   \n",
      "7        APJ 2024-02-07               11          264       FY25   \n",
      "10       APJ 2024-02-07               12          146       FY25   \n",
      "12       APJ 2024-02-07               13           97       FY25   \n",
      "...      ...        ...              ...          ...        ...   \n",
      "11870    APJ 2024-07-29                5          601       FY25   \n",
      "11872    APJ 2024-07-29                6          635       FY25   \n",
      "11876    APJ 2024-07-29                7          869       FY25   \n",
      "11879    APJ 2024-07-29                8          776       FY25   \n",
      "11883    APJ 2024-07-29                9          799       FY25   \n",
      "\n",
      "      FISCALQUARTER FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
      "2                Q1         M01       WK01  Wednesday 2024-02-07 09:00:00  \n",
      "4                Q1         M01       WK01  Wednesday 2024-02-07 10:00:00  \n",
      "7                Q1         M01       WK01  Wednesday 2024-02-07 11:00:00  \n",
      "10               Q1         M01       WK01  Wednesday 2024-02-07 12:00:00  \n",
      "12               Q1         M01       WK01  Wednesday 2024-02-07 13:00:00  \n",
      "...             ...         ...        ...        ...                 ...  \n",
      "11870            Q2         M06       WK26  Monday    2024-07-29 05:00:00  \n",
      "11872            Q2         M06       WK26  Monday    2024-07-29 06:00:00  \n",
      "11876            Q2         M06       WK26  Monday    2024-07-29 07:00:00  \n",
      "11879            Q2         M06       WK26  Monday    2024-07-29 08:00:00  \n",
      "11883            Q2         M06       WK26  Monday    2024-07-29 09:00:00  \n",
      "\n",
      "[3942 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separate dataframes for each region\n",
    "emea_df = df[df[\"REGION\"] == \"EMEA\"]\n",
    "dao_df = df[df[\"REGION\"] == \"DAO\"]\n",
    "apj_df = df[df[\"REGION\"] == \"APJ\"]\n",
    "\n",
    "# Print the dataframes\n",
    "print(\"EMEA DataFrame:\")\n",
    "print(emea_df)\n",
    "print(\"\\nDAO DataFrame:\")\n",
    "print(dao_df)\n",
    "print(\"\\nAPJ DataFrame:\")\n",
    "print(apj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "125af797-7187-48e4-ab98-4f2a2f893b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:28: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data for EMEA saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:28: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data for DAO saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:28: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\3559714318.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data for APJ saved\n"
     ]
    }
   ],
   "source": [
    "# Missing Values imputations for 3 regions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming df is your original DataFrame with all regions\n",
    "emea_df = df[df[\"REGION\"] == \"EMEA\"]\n",
    "dao_df = df[df[\"REGION\"] == \"DAO\"]\n",
    "apj_df = df[df[\"REGION\"] == \"APJ\"]\n",
    "\n",
    "# Define a function for imputation\n",
    "def perform_imputation(df, region_name):\n",
    "    # Convert DateTime column to datetime format\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "\n",
    "    # Generate 1-hour intervals\n",
    "    start_date = df[\"DateTime\"].min()\n",
    "    end_date = df[\"DateTime\"].max()\n",
    "    hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
    "\n",
    "    # Create a new DataFrame with intervals\n",
    "    interval_df = pd.DataFrame({\"DateTime\": hour_intervals})\n",
    "\n",
    "    # Merge interval_df with original data\n",
    "    merged_df = pd.merge(interval_df, df, on=\"DateTime\", how=\"left\")\n",
    "\n",
    "    # Fill missing data based on available data\n",
    "    merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "    # Perform imputation for ORDER_COUNT using DAYNUM\n",
    "    daynum_order_count_avg = merged_df.groupby(\"DAYNUM\")[\"ORDER_COUNT\"].mean()\n",
    "    merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
    "\n",
    "    # Fill remaining columns based on data & time columns\n",
    "    merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n",
    "\n",
    "    # Save the imputed DataFrame to an Excel file\n",
    "    # output_path = f\"C:\\\\Users\\\\S_Munwar\\\\Downloads\\\\Final_Model_for_OIF\\\\{region_name}_imputated.xlsx\"\n",
    "    merged_df.to_excel(f\"{region_name}_imputated.xlsx\", index=False)\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    print(f\"Imputed data for {region_name} saved\")\n",
    "\n",
    "# Perform imputation for each region\n",
    "for region_df, region_name in zip([emea_df, dao_df, apj_df], [\"EMEA\", \"DAO\", \"APJ\"]):\n",
    "    perform_imputation(region_df, region_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059f5b19-4137-48cb-947a-9fbe2fe4558d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>PROCESSDAY</th>\n",
       "      <th>PROCESSDAY_HOUR</th>\n",
       "      <th>ORDER_COUNT</th>\n",
       "      <th>FISCALYEAR</th>\n",
       "      <th>FISCALQUARTER</th>\n",
       "      <th>FISCALMONTH</th>\n",
       "      <th>FISCALWEEK</th>\n",
       "      <th>DAYNUM</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>9</td>\n",
       "      <td>831</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>10</td>\n",
       "      <td>870</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>11</td>\n",
       "      <td>897</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>12</td>\n",
       "      <td>875</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EMEA</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>13</td>\n",
       "      <td>924</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2024-02-07 13:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
       "0    EMEA 2024-02-07                9          831       FY25            Q1   \n",
       "3    EMEA 2024-02-07               10          870       FY25            Q1   \n",
       "8    EMEA 2024-02-07               11          897       FY25            Q1   \n",
       "11   EMEA 2024-02-07               12          875       FY25            Q1   \n",
       "14   EMEA 2024-02-07               13          924       FY25            Q1   \n",
       "\n",
       "   FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
       "0          M01       WK01  Wednesday 2024-02-07 09:00:00  \n",
       "3          M01       WK01  Wednesday 2024-02-07 10:00:00  \n",
       "8          M01       WK01  Wednesday 2024-02-07 11:00:00  \n",
       "11         M01       WK01  Wednesday 2024-02-07 12:00:00  \n",
       "14         M01       WK01  Wednesday 2024-02-07 13:00:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emea_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f22f5c09-f9e5-4484-ba33-4aea6c672cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns for EMEA:\n",
      "             DateTime  ORDER_COUNT\n",
      "0 2024-02-07 09:00:00          831\n",
      "1 2024-02-07 10:00:00          870\n",
      "2 2024-02-07 11:00:00          897\n",
      "3 2024-02-07 12:00:00          875\n",
      "4 2024-02-07 13:00:00          924\n",
      "\n",
      "Selected columns for DAO:\n",
      "             DateTime  ORDER_COUNT\n",
      "0 2024-02-07 09:00:00           81\n",
      "1 2024-02-07 10:00:00          111\n",
      "2 2024-02-07 11:00:00          184\n",
      "3 2024-02-07 12:00:00          729\n",
      "4 2024-02-07 13:00:00          999\n",
      "\n",
      "Selected columns for APJ:\n",
      "             DateTime  ORDER_COUNT\n",
      "0 2024-02-07 09:00:00          508\n",
      "1 2024-02-07 10:00:00          377\n",
      "2 2024-02-07 11:00:00          264\n",
      "3 2024-02-07 12:00:00          146\n",
      "4 2024-02-07 13:00:00           97\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to select specific columns from a DataFrame\n",
    "def select_columns(df, columns):\n",
    "    return df[columns].reset_index(drop=True)\n",
    "\n",
    "# Define the columns to select\n",
    "selected_columns = [\"DateTime\", \"ORDER_COUNT\"]\n",
    "\n",
    "# Assuming emea_df, dao_df, and apj_df are your DataFrames for the EMEA, DAO, and APJ regions respectively\n",
    "# Apply the function to each DataFrame\n",
    "data_emea = select_columns(emea_df, selected_columns)\n",
    "data_dao = select_columns(dao_df, selected_columns)\n",
    "data_apj = select_columns(apj_df, selected_columns)\n",
    "\n",
    "# Now you have the selected columns for each region\n",
    "print(\"Selected columns for EMEA:\")\n",
    "print(data_emea.head())\n",
    "\n",
    "print(\"\\nSelected columns for DAO:\")\n",
    "print(data_dao.head())\n",
    "\n",
    "print(\"\\nSelected columns for APJ:\")\n",
    "print(data_apj.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf4d1b9-2c8e-45f4-854a-a4a4f0830b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMEA - Decision Tree MSE: 25732.49872611465\n",
      "EMEA - Random Forest MSE: 23387.572977217125\n",
      "EMEA - GBM MSE: 15767.482288249677\n",
      "EMEA - SVM MSE: 98493.4290528242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\316647103.py:60: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to ML_forecast_results_EMEA_.xlsx for EMEA\n",
      "DAO - Decision Tree MSE: 217490.0384489303\n",
      "DAO - Random Forest MSE: 203169.62128481606\n",
      "DAO - GBM MSE: 170714.9045625135\n",
      "DAO - SVM MSE: 1265506.4730170984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\316647103.py:60: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to ML_forecast_results_DAO_.xlsx for DAO\n",
      "APJ - Decision Tree MSE: 31357.539114209267\n",
      "APJ - Random Forest MSE: 28968.410454229248\n",
      "APJ - GBM MSE: 22700.83187484461\n",
      "APJ - SVM MSE: 83625.27922719096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\316647103.py:60: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to ML_forecast_results_APJ_.xlsx for APJ\n"
     ]
    }
   ],
   "source": [
    "# Forecasting Models for 3 Regions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def process_region(data, region_name):\n",
    "    # Feature engineering for seasonality\n",
    "    data['hour'] = data.index.hour\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    data['month'] = data.index.month\n",
    "\n",
    "    # Prepare features and target with seasonality\n",
    "    X = data[['hour', 'dayofweek', 'month']]  # Add more features as needed\n",
    "    y = data['ORDER_COUNT']\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train your models here (Decision Tree, Random Forest, Gradient Boosting, SVM)\n",
    "    # Decision Tree Regressor\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    dt_predictions = dt_model.predict(X_test)\n",
    "    dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "    print(f'{region_name} - Decision Tree MSE: {dt_mse}')\n",
    "\n",
    "    # Random Forest Regressor\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "    print(f'{region_name} - Random Forest MSE: {rf_mse}')\n",
    "\n",
    "    # Gradient Boosting Regressor\n",
    "    gbm_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    gbm_model.fit(X_train, y_train)\n",
    "    gbm_predictions = gbm_model.predict(X_test)\n",
    "    gbm_mse = mean_squared_error(y_test, gbm_predictions)\n",
    "    print(f'{region_name} - GBM MSE: {gbm_mse}')\n",
    "\n",
    "    # Support Vector Machine Regressor\n",
    "    svm_model = SVR(kernel='rbf')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_predictions = svm_model.predict(X_test)\n",
    "    svm_mse = mean_squared_error(y_test, svm_predictions)\n",
    "    print(f'{region_name} - SVM MSE: {svm_mse}')\n",
    "\n",
    "    # Combine actual and forecasted values into DataFrames for comparison\n",
    "    actual_vs_forecasted_dt = pd.DataFrame({'Actual': y_test, 'Forecasted_DT': dt_predictions})\n",
    "    actual_vs_forecasted_rf = pd.DataFrame({'Actual': y_test, 'Forecasted_RF': rf_predictions})\n",
    "    actual_vs_forecasted_gbm = pd.DataFrame({'Actual': y_test, 'Forecasted_GBM': gbm_predictions})\n",
    "    actual_vs_forecasted_svm = pd.DataFrame({'Actual': y_test, 'Forecasted_SVM': svm_predictions})\n",
    "\n",
    "    # Extend the datetime index for the next 100 future values with 1-hour interval\n",
    "    last_timestamp = data.index[-1]\n",
    "    future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n",
    "\n",
    "    # Create a DataFrame for future dates and engineer seasonality features\n",
    "    future_df = pd.DataFrame(index=future_dates)\n",
    "    future_df['hour'] = future_df.index.hour\n",
    "    future_df['dayofweek'] = future_df.index.dayofweek\n",
    "    future_df['month'] = future_df.index.month\n",
    "\n",
    "    # Predict the next 100 future values using each model\n",
    "    future_predictions_dt = dt_model.predict(future_df)\n",
    "    future_predictions_rf = rf_model.predict(future_df)\n",
    "    future_predictions_gbm = gbm_model.predict(future_df)\n",
    "    future_predictions_svm = svm_model.predict(future_df)\n",
    "\n",
    "    # Create a DataFrame for the future predictions\n",
    "    future_predictions_df = pd.DataFrame({\n",
    "        'DateTime': future_dates,\n",
    "        'Forecasted_DT': future_predictions_dt,\n",
    "        'Forecasted_RF': future_predictions_rf,\n",
    "        'Forecasted_GBM': future_predictions_gbm,\n",
    "        'Forecasted_SVM': future_predictions_svm\n",
    "    })\n",
    "\n",
    "    # Set the DateTime as the index\n",
    "    future_predictions_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "    # Combine actual vs forecasted and future forecasted values into a single DataFrame\n",
    "    combined_results_df = pd.concat([\n",
    "        actual_vs_forecasted_dt,\n",
    "        actual_vs_forecasted_rf[['Forecasted_RF']],\n",
    "        actual_vs_forecasted_gbm[['Forecasted_GBM']],\n",
    "        actual_vs_forecasted_svm[['Forecasted_SVM']],\n",
    "        future_predictions_df\n",
    "    ], axis=1)\n",
    "\n",
    "    # Define the output path for the Excel file\n",
    "    output_excel_path = f'ML_forecast_results_{region_name}_.xlsx'\n",
    "\n",
    "    # Export the DataFrame to an Excel file\n",
    "    combined_results_df.to_excel(output_excel_path, index=True)\n",
    "\n",
    "    print(f\"Data exported to {output_excel_path} for {region_name}\")\n",
    "\n",
    "# Load your datasets\n",
    "data_emea = pd.DataFrame(data_emea)\n",
    "data_emea['DateTime'] = pd.to_datetime(data_emea['DateTime'])\n",
    "data_emea.set_index('DateTime', inplace=True)\n",
    "data_dao = pd.DataFrame(data_dao)\n",
    "data_dao['DateTime'] = pd.to_datetime(data_dao['DateTime'])\n",
    "data_dao.set_index('DateTime', inplace=True)\n",
    "data_apj = pd.DataFrame(data_apj)\n",
    "data_apj['DateTime'] = pd.to_datetime(data_apj['DateTime'])\n",
    "data_apj.set_index('DateTime', inplace=True)\n",
    "\n",
    "\n",
    "# Process each region\n",
    "process_region(data_emea, 'EMEA')\n",
    "process_region(data_dao, 'DAO')\n",
    "process_region(data_apj, 'APJ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b29f6c-ad72-4cfc-8645-900171f48c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33179fbc-e2da-40ad-b135-143ccdd138a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04277fe5-a3e2-42ee-a35c-ed41dce53141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1729b1-9d35-476a-993b-ded80d9f6420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f2ef9-79cf-44d0-ac4a-4d5e2b553105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565335e-a4ac-493b-b803-bbe1c25411dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc97cdc-6aef-4e5c-b6df-5cad4e129d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73928511-8aab-4b9b-a172-0ead2b4f8fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
