{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1cda694-0f24-41d5-ad9d-e3739dc4ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import oracledb\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "import re\n",
    "import webbrowser\n",
    " \n",
    "#SCRE\n",
    "username = 'svcGOCUI'\n",
    "password = 'DELL2023support#'\n",
    "host = 'gocplorlvpr18.amer.dell.com'\n",
    "port = '1521'\n",
    "service_name = 'gooap_rw_oud_tls.prd.amer.dell.com'\n",
    " \n",
    "#DAO GE4 SIT\n",
    "# dbname=\"DAO_GE4\"\n",
    "# username = 'SIT_BROWSER'\n",
    "# password = 'browse_s1t'\n",
    "# host = 'udmnlorrrsi2a01.amer.dell.com'\n",
    "# port = '1521'\n",
    "# service_name = 'fdr4s.sit.amer.dell.com'\n",
    "\n",
    "def Retrive_VectorData(region):\n",
    "    region =region.upper()\n",
    "    excel_name=\"Input_Order_Incoming_Data.xlsx\"\n",
    "    dsn = oracledb.makedsn(host, port, service_name=service_name)\n",
    "    try :\n",
    "        print(\"conn\")\n",
    "        connection = oracledb.connect(user=username, password=password, dsn=dsn)   \n",
    "        print(\"Connected to Oracle Database\")\n",
    "        cursor = connection.cursor()\n",
    "        # query = '''SELECT t.owner || '.' || t.table_name AS Table_Name,c.column_name as Column_Name FROM all_tables t \n",
    "        # JOIN all_tab_columns c ON t.table_name = c.table_name  ORDER BY t.table_name, c.column_name'''\n",
    " \n",
    "        query = f'''select a.region, to_char(a.processdate_utc,'yyyymmdd') processday,to_char(a.processdate_utc,'hh24') as processday_hour,\n",
    "a.order_count,b.fiscalyear,b.fiscalquarter,b.fiscalmonth,b.fiscalweek,to_char(a.processdate_utc,'Day') as DayNum\n",
    "  from work.tb_orderprocess_effectiveness a,work.tb_fiscalcalendar b\n",
    "where to_char(a.processdate_utc,'yyyymmdd') between b.startdate and b.enddate\n",
    "   and a.functionname = 'Order Incoming'\n",
    "   and datatype = 'NEW'\n",
    "   and vendor = 'ALL'\n",
    "   AND REGION = '{region}'\n",
    "order by a.processdate_utc asc'''\n",
    " \n",
    "        cursor.execute(query)\n",
    " \n",
    "        rows = cursor.fetchall()\n",
    "        column_names = [desc[0] for desc in cursor.description]\n",
    "        data = pd.DataFrame(rows,columns=column_names)\n",
    "        print(excel_name)\n",
    "        data.to_excel(excel_name,index=False)\n",
    "        table = tabulate(rows, headers=column_names, tablefmt=\"pretty\")\n",
    "        print(data)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "       print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n",
    "            print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce515e79-4d00-40b4-849e-7a117145d808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conn\n",
      "Connected to Oracle Database\n",
      "Input_Order_Incoming_Data.xlsx\n",
      "     REGION PROCESSDAY PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
      "0       APJ   20240207              09          508       FY25            Q1   \n",
      "1       APJ   20240207              10          377       FY25            Q1   \n",
      "2       APJ   20240207              11          264       FY25            Q1   \n",
      "3       APJ   20240207              12          146       FY25            Q1   \n",
      "4       APJ   20240207              13           97       FY25            Q1   \n",
      "...     ...        ...             ...          ...        ...           ...   \n",
      "3938    APJ   20240729              06          635       FY25            Q2   \n",
      "3939    APJ   20240729              07          869       FY25            Q2   \n",
      "3940    APJ   20240729              08          776       FY25            Q2   \n",
      "3941    APJ   20240729              09          799       FY25            Q2   \n",
      "3942    APJ   20240729              10          502       FY25            Q2   \n",
      "\n",
      "     FISCALMONTH FISCALWEEK     DAYNUM  \n",
      "0            M01       WK01  Wednesday  \n",
      "1            M01       WK01  Wednesday  \n",
      "2            M01       WK01  Wednesday  \n",
      "3            M01       WK01  Wednesday  \n",
      "4            M01       WK01  Wednesday  \n",
      "...          ...        ...        ...  \n",
      "3938         M06       WK26  Monday     \n",
      "3939         M06       WK26  Monday     \n",
      "3940         M06       WK26  Monday     \n",
      "3941         M06       WK26  Monday     \n",
      "3942         M06       WK26  Monday     \n",
      "\n",
      "[3943 rows x 9 columns]\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "region = 'apj'\n",
    "region = region.upper()\n",
    "data = Retrive_VectorData(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b7a4e8f-9d22-4514-84ff-97c2d6e92b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>PROCESSDAY</th>\n",
       "      <th>PROCESSDAY_HOUR</th>\n",
       "      <th>ORDER_COUNT</th>\n",
       "      <th>FISCALYEAR</th>\n",
       "      <th>FISCALQUARTER</th>\n",
       "      <th>FISCALMONTH</th>\n",
       "      <th>FISCALWEEK</th>\n",
       "      <th>DAYNUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>09</td>\n",
       "      <td>508</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>10</td>\n",
       "      <td>377</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>11</td>\n",
       "      <td>264</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>12</td>\n",
       "      <td>146</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APJ</td>\n",
       "      <td>20240207</td>\n",
       "      <td>13</td>\n",
       "      <td>97</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REGION PROCESSDAY PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
       "0    APJ   20240207              09          508       FY25            Q1   \n",
       "1    APJ   20240207              10          377       FY25            Q1   \n",
       "2    APJ   20240207              11          264       FY25            Q1   \n",
       "3    APJ   20240207              12          146       FY25            Q1   \n",
       "4    APJ   20240207              13           97       FY25            Q1   \n",
       "\n",
       "  FISCALMONTH FISCALWEEK     DAYNUM  \n",
       "0         M01       WK01  Wednesday  \n",
       "1         M01       WK01  Wednesday  \n",
       "2         M01       WK01  Wednesday  \n",
       "3         M01       WK01  Wednesday  \n",
       "4         M01       WK01  Wednesday  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3a8ff-55ac-4e5a-b4c2-78ed05192c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uploading out put file into SQL DB\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# from sqlalchemy.types import Integer, String, DateTime, Numeric\n",
    "# import cx_Oracle\n",
    " \n",
    "# #SCRE\n",
    "# username = 'svcGOCUI'\n",
    "# password = 'DELL2023support#'\n",
    "# host = 'gocplorlvpr18.amer.dell.com'\n",
    "# port = '1521'\n",
    "# service_name = 'gooap_rw_oud_tls.prd.amer.dell.com'\n",
    "# dsn = oracledb.makedsn(host, port, service_name=service_name)\n",
    " \n",
    "# engine = create_engine(f'oracle+cx_oracle://{username}:{password}@{dsn}')\n",
    "# dtype = {\n",
    "#     'REGION': String(256), \n",
    "#     'FORECAST_DATE': DateTime,\n",
    "#     'MODEL1': Numeric,\n",
    "#     'MODEL2': Numeric,\n",
    "#     'MODEL3': Numeric,\n",
    "#     'MODEL4': Numeric,\n",
    "#     'MODEL5': Numeric,\n",
    "#     'ACTUALORDERUNIT': Numeric,\n",
    "#     'CREATED_DATE': DateTime,\n",
    "#     'UPDATED_DATE': DateTime,\n",
    "# }\n",
    " \n",
    "# try:\n",
    "#     data = pd.read_csv(r\"C:/Users/S_Munwar/Downloads/Final_Model_for_OIF/Future_forecasted_OIF_SQL.csv\")\n",
    "#     print(type(data))\n",
    "#     data['FORECAST_DATE'] = pd.to_datetime(data['FORECAST_DATE'])\n",
    "#     data['CREATED_DATE'] = pd.to_datetime(data['CREATED_DATE'])\n",
    "#     data['UPDATED_DATE'] = pd.to_datetime(data['UPDATED_DATE'])\n",
    "#     print(type(data))\n",
    "#     data.to_sql('tb_orderprocess_effectiveness_forecast',schema ='work', con=engine, if_exists='append', index=False)\n",
    "#     print(\"added successfully\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "# finally:\n",
    "#     engine.dispose()\n",
    "#     print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32952368-3e48-4eba-982f-a023c5fa3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert PROCESSDAY to proper date format\n",
    "data[\"PROCESSDAY\"] = pd.to_datetime(data[\"PROCESSDAY\"], format=\"%Y%m%d\")\n",
    "\n",
    "data[\"PROCESSDAY_HOUR\"] = data[\"PROCESSDAY_HOUR\"].astype(int)\n",
    "# Create a new column combining PROCESSDAY and PROCESSDAY_HOUR\n",
    "data[\"DateTime\"] = data[\"PROCESSDAY\"] + pd.to_timedelta(data[\"PROCESSDAY_HOUR\"], unit=\"h\")\n",
    "\n",
    "# Drop the index column\n",
    "#data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "473c278f-71a0-48e6-8a82-34bace81b1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APJ\n"
     ]
    }
   ],
   "source": [
    "#df= data.drop(columns=['PROCESSDAY', 'PROCESSDAY'])\n",
    "df=data\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "434e8489-d6bf-4acf-8734-d966e65d051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APJ  DataFrame:\n",
      "     REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT FISCALYEAR FISCALQUARTER  \\\n",
      "0       APJ 2024-02-07                9          508       FY25            Q1   \n",
      "1       APJ 2024-02-07               10          377       FY25            Q1   \n",
      "2       APJ 2024-02-07               11          264       FY25            Q1   \n",
      "3       APJ 2024-02-07               12          146       FY25            Q1   \n",
      "4       APJ 2024-02-07               13           97       FY25            Q1   \n",
      "...     ...        ...              ...          ...        ...           ...   \n",
      "3938    APJ 2024-07-29                6          635       FY25            Q2   \n",
      "3939    APJ 2024-07-29                7          869       FY25            Q2   \n",
      "3940    APJ 2024-07-29                8          776       FY25            Q2   \n",
      "3941    APJ 2024-07-29                9          799       FY25            Q2   \n",
      "3942    APJ 2024-07-29               10          502       FY25            Q2   \n",
      "\n",
      "     FISCALMONTH FISCALWEEK     DAYNUM            DateTime  \n",
      "0            M01       WK01  Wednesday 2024-02-07 09:00:00  \n",
      "1            M01       WK01  Wednesday 2024-02-07 10:00:00  \n",
      "2            M01       WK01  Wednesday 2024-02-07 11:00:00  \n",
      "3            M01       WK01  Wednesday 2024-02-07 12:00:00  \n",
      "4            M01       WK01  Wednesday 2024-02-07 13:00:00  \n",
      "...          ...        ...        ...                 ...  \n",
      "3938         M06       WK26  Monday    2024-07-29 06:00:00  \n",
      "3939         M06       WK26  Monday    2024-07-29 07:00:00  \n",
      "3940         M06       WK26  Monday    2024-07-29 08:00:00  \n",
      "3941         M06       WK26  Monday    2024-07-29 09:00:00  \n",
      "3942         M06       WK26  Monday    2024-07-29 10:00:00  \n",
      "\n",
      "[3943 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separate dataframes for each region\n",
    "\n",
    "df = df[df[\"REGION\"] == region]\n",
    "# emea_df = df[df[\"REGION\"] == \"EMEA\"]\n",
    "# dao_df = df[df[\"REGION\"] == \"DAO\"]\n",
    "# apj_df = df[df[\"REGION\"] == \"APJ\"]\n",
    "\n",
    "# Print the dataframes\n",
    "print(f\"{region}  DataFrame:\")\n",
    "print(df)\n",
    "# print(\"\\nDAO DataFrame:\")\n",
    "# print(dao_df)\n",
    "# print(\"\\nAPJ DataFrame:\")\n",
    "# print(apj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "125af797-7187-48e4-ab98-4f2a2f893b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APJ\n",
      "                DateTime REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT  \\\n",
      "0    2024-02-07 09:00:00    APJ 2024-02-07              9.0        508.0   \n",
      "1    2024-02-07 10:00:00    APJ 2024-02-07             10.0        377.0   \n",
      "2    2024-02-07 11:00:00    APJ 2024-02-07             11.0        264.0   \n",
      "3    2024-02-07 12:00:00    APJ 2024-02-07             12.0        146.0   \n",
      "4    2024-02-07 13:00:00    APJ 2024-02-07             13.0         97.0   \n",
      "...                  ...    ...        ...              ...          ...   \n",
      "4149 2024-07-29 06:00:00    APJ 2024-07-29              6.0        635.0   \n",
      "4150 2024-07-29 07:00:00    APJ 2024-07-29              7.0        869.0   \n",
      "4151 2024-07-29 08:00:00    APJ 2024-07-29              8.0        776.0   \n",
      "4152 2024-07-29 09:00:00    APJ 2024-07-29              9.0        799.0   \n",
      "4153 2024-07-29 10:00:00    APJ 2024-07-29             10.0        502.0   \n",
      "\n",
      "     FISCALYEAR FISCALQUARTER FISCALMONTH FISCALWEEK     DAYNUM  \n",
      "0          FY25            Q1         M01       WK01  Wednesday  \n",
      "1          FY25            Q1         M01       WK01  Wednesday  \n",
      "2          FY25            Q1         M01       WK01  Wednesday  \n",
      "3          FY25            Q1         M01       WK01  Wednesday  \n",
      "4          FY25            Q1         M01       WK01  Wednesday  \n",
      "...         ...           ...         ...        ...        ...  \n",
      "4149       FY25            Q2         M06       WK26  Monday     \n",
      "4150       FY25            Q2         M06       WK26  Monday     \n",
      "4151       FY25            Q2         M06       WK26  Monday     \n",
      "4152       FY25            Q2         M06       WK26  Monday     \n",
      "4153       FY25            Q2         M06       WK26  Monday     \n",
      "\n",
      "[4154 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:21: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:34: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:35: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2834530333.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data for APJ saved\n"
     ]
    }
   ],
   "source": [
    "# Missing Values imputations for 3 regions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming df is your original DataFrame with all regions\n",
    "df = df[df[\"REGION\"] == region]\n",
    "\n",
    "# emea_df = df[df[\"REGION\"] == \"EMEA\"]\n",
    "# dao_df = df[df[\"REGION\"] == \"DAO\"]\n",
    "# apj_df = df[df[\"REGION\"] == \"APJ\"]\n",
    "\n",
    "# Define a function for imputation\n",
    "def perform_imputation(df, region_name):\n",
    "    # Convert DateTime column to datetime format\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "\n",
    "    # Generate 1-hour intervals\n",
    "    start_date = df[\"DateTime\"].min()\n",
    "    end_date = df[\"DateTime\"].max()\n",
    "    hour_intervals = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n",
    "\n",
    "    # Create a new DataFrame with intervals\n",
    "    interval_df = pd.DataFrame({\"DateTime\": hour_intervals})\n",
    "\n",
    "    # Merge interval_df with original data\n",
    "    merged_df = pd.merge(interval_df, df, on=\"DateTime\", how=\"left\")\n",
    "\n",
    "    # Fill missing data based on available data\n",
    "    merged_df[\"REGION\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALYEAR\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALQUARTER\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALMONTH\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"FISCALWEEK\"].fillna(method=\"ffill\", inplace=True)\n",
    "    merged_df[\"DAYNUM\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "    # Perform imputation for ORDER_COUNT using DAYNUM\n",
    "    daynum_order_count_avg = merged_df.groupby(\"DAYNUM\")[\"ORDER_COUNT\"].mean()\n",
    "    merged_df[\"ORDER_COUNT\"].fillna(merged_df[\"DAYNUM\"].map(daynum_order_count_avg), inplace=True)\n",
    "\n",
    "    # Fill remaining columns based on data & time columns\n",
    "    merged_df[\"PROCESSDAY_HOUR\"].fillna(merged_df[\"DateTime\"].dt.hour, inplace=True)\n",
    "\n",
    "    # Save the imputed DataFrame to an Excel file\n",
    "    # output_path = f\"C:\\\\Users\\\\S_Munwar\\\\Downloads\\\\Final_Model_for_OIF\\\\{region_name}_imputated.xlsx\"\n",
    "    return merged_df\n",
    "    \n",
    "\n",
    "# Perform imputation for each region\n",
    "# for region_df, region_name in zip([emea_df, dao_df, apj_df], [\"EMEA\", \"DAO\", \"APJ\"]):\n",
    "#     print(region_name)\n",
    "#     perform_imputation(region_df, region_name)\n",
    "\n",
    "print(region)\n",
    "imputed_df = perform_imputation(df, region)\n",
    "\n",
    "print(imputed_df)\n",
    "imputed_df.to_excel(f\"{region}_imputated.xlsx\", index=False)\n",
    "# Print the resulting DataFrame\n",
    "print(f\"Imputed data for {region} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "059f5b19-4137-48cb-947a-9fbe2fe4558d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>REGION</th>\n",
       "      <th>PROCESSDAY</th>\n",
       "      <th>PROCESSDAY_HOUR</th>\n",
       "      <th>ORDER_COUNT</th>\n",
       "      <th>FISCALYEAR</th>\n",
       "      <th>FISCALQUARTER</th>\n",
       "      <th>FISCALMONTH</th>\n",
       "      <th>FISCALWEEK</th>\n",
       "      <th>DAYNUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-07 09:00:00</td>\n",
       "      <td>APJ</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-07 10:00:00</td>\n",
       "      <td>APJ</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>10.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-07 11:00:00</td>\n",
       "      <td>APJ</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>11.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-07 12:00:00</td>\n",
       "      <td>APJ</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>12.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-07 13:00:00</td>\n",
       "      <td>APJ</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>FY25</td>\n",
       "      <td>Q1</td>\n",
       "      <td>M01</td>\n",
       "      <td>WK01</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime REGION PROCESSDAY  PROCESSDAY_HOUR  ORDER_COUNT  \\\n",
       "0 2024-02-07 09:00:00    APJ 2024-02-07              9.0        508.0   \n",
       "1 2024-02-07 10:00:00    APJ 2024-02-07             10.0        377.0   \n",
       "2 2024-02-07 11:00:00    APJ 2024-02-07             11.0        264.0   \n",
       "3 2024-02-07 12:00:00    APJ 2024-02-07             12.0        146.0   \n",
       "4 2024-02-07 13:00:00    APJ 2024-02-07             13.0         97.0   \n",
       "\n",
       "  FISCALYEAR FISCALQUARTER FISCALMONTH FISCALWEEK     DAYNUM  \n",
       "0       FY25            Q1         M01       WK01  Wednesday  \n",
       "1       FY25            Q1         M01       WK01  Wednesday  \n",
       "2       FY25            Q1         M01       WK01  Wednesday  \n",
       "3       FY25            Q1         M01       WK01  Wednesday  \n",
       "4       FY25            Q1         M01       WK01  Wednesday  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f22f5c09-f9e5-4484-ba33-4aea6c672cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns for APJ:\n",
      "             DateTime  ORDER_COUNT\n",
      "0 2024-02-07 09:00:00        508.0\n",
      "1 2024-02-07 10:00:00        377.0\n",
      "2 2024-02-07 11:00:00        264.0\n",
      "3 2024-02-07 12:00:00        146.0\n",
      "4 2024-02-07 13:00:00         97.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to select specific columns from a DataFrame\n",
    "def select_columns(df, columns):\n",
    "    return df[columns].reset_index(drop=True)\n",
    "\n",
    "# Define the columns to select\n",
    "selected_columns = [\"DateTime\", \"ORDER_COUNT\"]\n",
    "\n",
    "# Assuming emea_df, dao_df, and apj_df are your DataFrames for the EMEA, DAO, and APJ regions respectively\n",
    "# Apply the function to each DataFrame\n",
    "data_df = select_columns(imputed_df, selected_columns)\n",
    "\n",
    "# data_emea = select_columns(emea_df, selected_columns)\n",
    "# data_dao = select_columns(dao_df, selected_columns)\n",
    "# data_apj = select_columns(apj_df, selected_columns)\n",
    "\n",
    "# Now you have the selected columns for each region\n",
    "print(f\"Selected columns for {region}:\")\n",
    "print(data_df.head())\n",
    "\n",
    "# print(\"\\nSelected columns for DAO:\")\n",
    "# print(data_dao.head())\n",
    "\n",
    "# print(\"\\nSelected columns for APJ:\")\n",
    "# print(data_apj.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7bf4d1b9-2c8e-45f4-854a-a4a4f0830b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APJ - Decision Tree MSE: 26438.653661910306\n",
      "APJ - Random Forest MSE: 25471.165728655287\n",
      "APJ - GBM MSE: 23781.485937879428\n",
      "APJ - SVM MSE: 90515.51213771291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BharathKumar_Bellam\\AppData\\Local\\Temp\\ipykernel_33264\\2146460868.py:60: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to ML_forecast_results_APJ_.xlsx for APJ\n"
     ]
    }
   ],
   "source": [
    "# Forecasting Models for 3 Regions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def process_region(data, region_name):\n",
    "    # Feature engineering for seasonality\n",
    "    data['hour'] = data.index.hour\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    data['month'] = data.index.month\n",
    "\n",
    "    # Prepare features and target with seasonality\n",
    "    X = data[['hour', 'dayofweek', 'month']]  # Add more features as needed\n",
    "    y = data['ORDER_COUNT']\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train your models here (Decision Tree, Random Forest, Gradient Boosting, SVM)\n",
    "    # Decision Tree Regressor\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    dt_predictions = dt_model.predict(X_test)\n",
    "    dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "    print(f'{region_name} - Decision Tree MSE: {dt_mse}')\n",
    "\n",
    "    # Random Forest Regressor\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "    print(f'{region_name} - Random Forest MSE: {rf_mse}')\n",
    "\n",
    "    # Gradient Boosting Regressor\n",
    "    gbm_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    gbm_model.fit(X_train, y_train)\n",
    "    gbm_predictions = gbm_model.predict(X_test)\n",
    "    gbm_mse = mean_squared_error(y_test, gbm_predictions)\n",
    "    print(f'{region_name} - GBM MSE: {gbm_mse}')\n",
    "\n",
    "    # Support Vector Machine Regressor\n",
    "    svm_model = SVR(kernel='rbf')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_predictions = svm_model.predict(X_test)\n",
    "    svm_mse = mean_squared_error(y_test, svm_predictions)\n",
    "    print(f'{region_name} - SVM MSE: {svm_mse}')\n",
    "\n",
    "    # Combine actual and forecasted values into DataFrames for comparison\n",
    "    actual_vs_forecasted_dt = pd.DataFrame({'Actual': y_test, 'Forecasted_DT': dt_predictions})\n",
    "    actual_vs_forecasted_rf = pd.DataFrame({'Actual': y_test, 'Forecasted_RF': rf_predictions})\n",
    "    actual_vs_forecasted_gbm = pd.DataFrame({'Actual': y_test, 'Forecasted_GBM': gbm_predictions})\n",
    "    actual_vs_forecasted_svm = pd.DataFrame({'Actual': y_test, 'Forecasted_SVM': svm_predictions})\n",
    "\n",
    "    # Extend the datetime index for the next 100 future values with 1-hour interval\n",
    "    last_timestamp = data.index[-1]\n",
    "    future_dates = pd.date_range(start=last_timestamp, periods=167, freq='H')[1:]\n",
    "\n",
    "    # Create a DataFrame for future dates and engineer seasonality features\n",
    "    future_df = pd.DataFrame(index=future_dates)\n",
    "    future_df['hour'] = future_df.index.hour\n",
    "    future_df['dayofweek'] = future_df.index.dayofweek\n",
    "    future_df['month'] = future_df.index.month\n",
    "\n",
    "    # Predict the next 100 future values using each model\n",
    "    future_predictions_dt = dt_model.predict(future_df)\n",
    "    future_predictions_rf = rf_model.predict(future_df)\n",
    "    future_predictions_gbm = gbm_model.predict(future_df)\n",
    "    future_predictions_svm = svm_model.predict(future_df)\n",
    "\n",
    "    # Create a DataFrame for the future predictions\n",
    "    future_predictions_df = pd.DataFrame({\n",
    "        'DateTime': future_dates,\n",
    "        'Forecasted_DT': future_predictions_dt,\n",
    "        'Forecasted_RF': future_predictions_rf,\n",
    "        'Forecasted_GBM': future_predictions_gbm,\n",
    "        'Forecasted_SVM': future_predictions_svm\n",
    "    })\n",
    "\n",
    "    # Set the DateTime as the index\n",
    "    future_predictions_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "    # Combine actual vs forecasted and future forecasted values into a single DataFrame\n",
    "    combined_results_df = pd.concat([\n",
    "        actual_vs_forecasted_dt,\n",
    "        actual_vs_forecasted_rf[['Forecasted_RF']],\n",
    "        actual_vs_forecasted_gbm[['Forecasted_GBM']],\n",
    "        actual_vs_forecasted_svm[['Forecasted_SVM']],\n",
    "        future_predictions_df\n",
    "    ], axis=1)\n",
    "\n",
    "    # Define the output path for the Excel file\n",
    "    output_excel_path = f'ML_forecast_results_{region_name}_.xlsx'\n",
    "\n",
    "    # Export the DataFrame to an Excel file\n",
    "    combined_results_df.to_excel(output_excel_path, index=True)\n",
    "\n",
    "    print(f\"Data exported to {output_excel_path} for {region_name}\")\n",
    "\n",
    "# Load your datasets\n",
    "data_df = pd.DataFrame(data_df)\n",
    "data_df['DateTime'] = pd.to_datetime(data_df['DateTime'])\n",
    "data_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process each region\n",
    "process_region(data_df, region)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b29f6c-ad72-4cfc-8645-900171f48c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
